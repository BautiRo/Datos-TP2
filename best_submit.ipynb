{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import squarify # pip install squarify\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suprimimos la notacion cientifica en los outputs\n",
    "pd.options.display.float_format = '{:20,.2f}'.format\n",
    "\n",
    "train_values = pd.read_csv('train_values.csv', index_col='building_id')\n",
    "train_labels = pd.read_csv('train_labels.csv', index_col='building_id')\n",
    "test_values = pd.read_csv('test_values.csv', index_col='building_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom features\n",
    "\n",
    "Notamos que si utilizamos el csv que exportamos del notebook de feature engineering, por mas que utilicemos los mismos features, el modelo da un peor puntaje que cuando utilizamos el train_values.csv. Por lo tanto, esperando eliminar estos efectos negativos, calcularemos los features que vayamos a utilizar aqui mismo, copiando el codigo que hicimos en el notebook mencionado anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values['more_families_than_mean'] = train_values.apply(lambda x: x['count_families'] > 1.07, axis=1)\n",
    "test_values['more_families_than_mean'] = test_values.apply(lambda x: x['count_families'] > 1.07, axis=1)\n",
    "\n",
    "train_values['older_than_mean'] = train_values.apply(lambda x: x['age'] > 26.54, axis=1)\n",
    "test_values['older_than_mean'] = test_values.apply(lambda x: x['age'] > 26.55, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use(x):\n",
    "    if not x['has_secondary_use']: # Es una casa\n",
    "        return 1\n",
    "    if x['has_secondary_use_agriculture']: # Es de agricultura\n",
    "        return 2\n",
    "    if x['has_secondary_use_hotel']: # Es un hotel\n",
    "        return 3\n",
    "    if x['has_secondary_use_rental']: # Es de alquiler\n",
    "        return 4\n",
    "    if x['has_secondary_use_institution']: # Es una institucion\n",
    "        return 5\n",
    "    if x['has_secondary_use_school']: # Es una escuela\n",
    "        return 6\n",
    "    if x['has_secondary_use_industry']: # Es una industria\n",
    "        return 7\n",
    "    if x['has_secondary_use_health_post']: # Es un puesto de salud\n",
    "        return 8\n",
    "    if x['has_secondary_use_gov_office']: # Es una oficina de gobierno\n",
    "        return 9\n",
    "    if x['has_secondary_use_use_police']: # Es una estacion de policias\n",
    "        return 10\n",
    "    if x['has_secondary_use_other']: # tiene otro uso\n",
    "        return 11\n",
    "    \n",
    "train_values['use'] = train_values.apply(lambda x: use(x), axis=1)\n",
    "test_values['use'] = test_values.apply(lambda x: use(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values['height per area'] = train_values.height_percentage / train_values.area_percentage\n",
    "test_values['height per area'] = test_values.height_percentage / test_values.area_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = train_values[['has_superstructure_adobe_mud', 'has_superstructure_mud_mortar_stone',\n",
    "                       'has_superstructure_stone_flag', 'has_superstructure_cement_mortar_stone',\n",
    "                       'has_superstructure_mud_mortar_brick', 'has_superstructure_cement_mortar_brick',\n",
    "                       'has_superstructure_timber', 'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered',\n",
    "                       'has_superstructure_rc_engineered', 'has_superstructure_other']]\n",
    "train_values[\"cant_materials\"] = subset.sum(axis=1)\n",
    "\n",
    "subset_test = test_values[['has_superstructure_adobe_mud', 'has_superstructure_mud_mortar_stone',\n",
    "                       'has_superstructure_stone_flag', 'has_superstructure_cement_mortar_stone',\n",
    "                       'has_superstructure_mud_mortar_brick', 'has_superstructure_cement_mortar_brick',\n",
    "                       'has_superstructure_timber', 'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered',\n",
    "                       'has_superstructure_rc_engineered', 'has_superstructure_other']]\n",
    "test_values[\"cant_materials\"] = subset_test.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viendo esto podemos agregar otra columna que asigne 1 si tiene la cantidad pisos que resultó con daño considerable\n",
    "def bad_cant_floor(x):\n",
    "    if (x > 0 and x < 6) or x == 8:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "train_values['bad_cant_floor'] = train_values.apply(lambda x: bad_cant_floor(x['count_floors_pre_eq']), axis=1)\n",
    "test_values['bad_cant_floor'] = test_values.apply(lambda x: bad_cant_floor(x['count_floors_pre_eq']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values['has_good_foundation_type'] = train_values.apply(lambda x: 1 if x[\"foundation_type\"] in [\"i\",\"u\",\"w\"] else 0, axis=1)\n",
    "train_values['has_good_roof_type'] = train_values.apply(lambda x: 1 if x[\"roof_type\"] == \"x\" else 0, axis=1)\n",
    "train_values['has_good_ground_floor_type'] = train_values.apply(lambda x: 1 if x[\"ground_floor_type\"] == \"v\" else 0, axis=1)\n",
    "train_values['has_good_other_floor_type'] = train_values.apply(lambda x: 1 if x[\"other_floor_type\"] == \"s\" else 0, axis=1)\n",
    "\n",
    "test_values['has_good_foundation_type'] = test_values.apply(lambda x: 1 if x[\"foundation_type\"] in [\"i\",\"u\",\"w\"] else 0, axis=1)\n",
    "test_values['has_good_roof_type'] = test_values.apply(lambda x: 1 if x[\"roof_type\"] == \"x\" else 0, axis=1)\n",
    "test_values['has_good_ground_floor_type'] = test_values.apply(lambda x: 1 if x[\"ground_floor_type\"] == \"v\" else 0, axis=1)\n",
    "test_values['has_good_other_floor_type'] = test_values.apply(lambda x: 1 if x[\"other_floor_type\"] == \"s\" else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_of_region(x,l1,l2,l3):\n",
    "    if x['geo_level_1_id'] == l1:\n",
    "        if x['geo_level_2_id'] == l2:\n",
    "            if x['geo_level_3_id'] == l3:\n",
    "                return 3\n",
    "            else:\n",
    "                return 2\n",
    "        else:\n",
    "            return 1\n",
    "    else:\n",
    "        return 0   \n",
    "train_values['most_damaged_region'] = train_values.apply(lambda x: value_of_region(x,17,363,8236), axis=1)\n",
    "test_values['most_damaged_region'] = test_values.apply(lambda x: value_of_region(x,17,363,8236), axis=1)\n",
    "\n",
    "train_values['less_damaged_region'] = train_values.apply(lambda x: value_of_region(x,26,39,9133), axis=1)\n",
    "test_values['less_damaged_region'] = test_values.apply(lambda x: value_of_region(x,26,39,9133), axis=1)\n",
    "\n",
    "def has_the_most_damaged_combination(x):\n",
    "    if x['plan_configuration'] == 'n':\n",
    "        if x['has_superstructure_adobe_mud'] or x['has_superstructure_stone_flag'] or x['has_superstructure_mud_mortar_brick'] or x['has_superstructure_other']:\n",
    "            return 1\n",
    "    return 0\n",
    "train_values['has_most_damaged_construct_combination'] = train_values.\\\n",
    "apply(lambda x: has_the_most_damaged_combination(x), axis=1)\n",
    "\n",
    "test_values['has_most_damaged_construct_combination'] = test_values.\\\n",
    "apply(lambda x: has_the_most_damaged_combination(x), axis=1)\n",
    "\n",
    "most_used_train_material = train_values[['has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag',\n",
    "              'has_superstructure_cement_mortar_stone',\n",
    "              'has_superstructure_mud_mortar_brick',\n",
    "              'has_superstructure_cement_mortar_brick', 'has_superstructure_timber',\n",
    "              'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered',\n",
    "              'has_superstructure_rc_engineered', 'has_superstructure_other']].sum().sort_values(ascending=False).keys()[0]\n",
    "\n",
    "most_used_test_material = test_values[['has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag',\n",
    "              'has_superstructure_cement_mortar_stone',\n",
    "              'has_superstructure_mud_mortar_brick',\n",
    "              'has_superstructure_cement_mortar_brick', 'has_superstructure_timber',\n",
    "              'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered',\n",
    "              'has_superstructure_rc_engineered', 'has_superstructure_other']].sum().sort_values(ascending=False).keys()[0]\n",
    "\n",
    "train_values['has_most_used_material'] = train_values.apply(lambda x: x[most_used_train_material], axis=1)\n",
    "test_values['has_most_used_material'] = test_values.apply(lambda x: x[most_used_test_material], axis=1)\n",
    "\n",
    "least_used_train_material = train_values[['has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag',\n",
    "              'has_superstructure_cement_mortar_stone',\n",
    "              'has_superstructure_mud_mortar_brick',\n",
    "              'has_superstructure_cement_mortar_brick', 'has_superstructure_timber',\n",
    "              'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered',\n",
    "              'has_superstructure_rc_engineered', 'has_superstructure_other']].sum().sort_values().keys()[0]\n",
    "\n",
    "least_used_test_material = test_values[['has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag',\n",
    "              'has_superstructure_cement_mortar_stone',\n",
    "              'has_superstructure_mud_mortar_brick',\n",
    "              'has_superstructure_cement_mortar_brick', 'has_superstructure_timber',\n",
    "              'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered',\n",
    "              'has_superstructure_rc_engineered', 'has_superstructure_other']].sum().sort_values().keys()[0]\n",
    "\n",
    "train_values['has_least_used_material'] = train_values.apply(lambda x: x[least_used_train_material], axis=1)\n",
    "test_values['has_least_used_material'] = test_values.apply(lambda x: x[least_used_test_material], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['foundation_type', 'area_percentage', 'height_percentage', 'count_floors_pre_eq',\n",
    "                     'land_surface_condition', 'has_superstructure_cement_mortar_stone', 'age', 'geo_level_1_id',\n",
    "                     'geo_level_2_id','geo_level_3_id']#, 'height per area', 'cant_materials', 'bad_cant_floor']\n",
    "\n",
    "train_values_subset = train_values#[selected_features]\n",
    "test_values_subset = test_values#[selected_features]\n",
    "\n",
    "train_values_subset = pd.get_dummies(train_values_subset)\n",
    "test_values_subset = pd.get_dummies(test_values_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensamblador(estimadores,X, y):\n",
    "    eclf3 = VotingClassifier(estimators=[\n",
    "       ('xgb', estimadores[0]), ('rf', estimadores[1]), ('knn', estimadores[2]), ('dt', estimadores[3])],\n",
    "       voting='soft', weights=[0.5, 1, 0.4, 0.7],\n",
    "      flatten_transform=True)\n",
    "\n",
    "        \n",
    "        \n",
    "    votC_param_grid = {\n",
    "        'weights': [[1, 0.5, 1, 0.4], [1, 1, 1, 1]],\n",
    "        \n",
    "    }\n",
    "    \n",
    "    gsvotC = GridSearchCV(eclf3, param_grid = votC_param_grid, cv=4, scoring=\"f1_micro\", n_jobs= 4, verbose = 1)\n",
    "    print('Voting Classifier')\n",
    "    gsvotC.fit(X, y)\n",
    "    \n",
    "    \n",
    "    votC_best = gsvotC.best_estimator_\n",
    "\n",
    "    # Best score\n",
    "    \n",
    "    return votC_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   8 out of   8 | elapsed:  6.7min finished\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:40:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(colsample_bytree = 0.4, \n",
    "                        learning_rate = 0.36,\n",
    "                        max_depth = 5, \n",
    "                        alpha = 1,\n",
    "                        n_estimators = 100)\n",
    "rf_model = RandomForestClassifier(random_state=2018, n_estimators=100, min_samples_leaf=5)\n",
    "#mlp_model = MLPClassifier() Este no nos funciono muy bien\n",
    "knn_model = KNeighborsClassifier(n_neighbors=10)\n",
    "dt_model = DecisionTreeClassifier(max_features = None,\n",
    "                            max_depth = 45,\n",
    "                            min_samples_split = 3,\n",
    "                            min_samples_leaf = 30,\n",
    "                            random_state=42)\n",
    "ensamble = ensamblador([xgb_model,rf_model,knn_model,dt_model],train_values_subset, train_labels.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:42:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('xgb',\n",
       "                              XGBClassifier(alpha=1, base_score=None,\n",
       "                                            booster=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=0.4, gamma=None,\n",
       "                                            gpu_id=None, importance_type='gain',\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=0.36,\n",
       "                                            max_delta_step=None, max_depth=5,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimator...\n",
       "                                            reg_lambda=None,\n",
       "                                            scale_pos_weight=None,\n",
       "                                            subsample=None, tree_method=None,\n",
       "                                            validate_parameters=None,\n",
       "                                            verbosity=None)),\n",
       "                             ('rf',\n",
       "                              RandomForestClassifier(min_samples_leaf=5,\n",
       "                                                     random_state=2018)),\n",
       "                             ('knn', KNeighborsClassifier(n_neighbors=10)),\n",
       "                             ('dt',\n",
       "                              DecisionTreeClassifier(max_depth=45,\n",
       "                                                     min_samples_leaf=30,\n",
       "                                                     min_samples_split=3,\n",
       "                                                     random_state=42))],\n",
       "                 voting='soft', weights=[1, 0.5, 1, 0.4])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensamble.fit(train_values_subset, train_labels.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = ensamble.predict(train_values_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7766010107405574"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(train_labels, predictions_train, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = ensamble.predict(test_values_subset)\n",
    "submission_format = pd.read_csv('submission_format.csv', index_col='building_id')\n",
    "my_submission = pd.DataFrame(data=predictions, columns=submission_format.columns, index=submission_format.index)\n",
    "my_submission.to_csv('submission_27_7_E_6.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este último tuvo un score de 0.7412 en driven data y 0.7764 en f1 score.\n",
    "Se utilizaron todos los feates, no se hizo grid search para los hiperparámetros de los modelos pero si para los pesos de los algoritmos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anteriormente se hizo otro.\n",
    "Este tuvo un valor de 0.7368 en driven data y 0.7764 en f1.\n",
    "\n",
    "Se utilizaron todos los features pero no se hizo grid search para los hiperparámetros de los modelos ni para los pesos de los algoritmos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
